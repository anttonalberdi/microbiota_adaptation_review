}
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Extract keywords
key_res <- keyword_search(pdftext, keyword = keywords)
key_res <- c()
dim(key_res)
####
# Get list of dois
####
doilist <- list.files(path = "papers", pattern = ".pdf",full.names=FALSE)
doilist <- gsub(".pdf","",doilist)
####
# Iterate across dois
####
for(doi in doilist){
print(paste0("Processing paper: ",doi))
#Extract text
pdftext <- c()
tryCatch({
pdftext <- tabulizer::extract_text(paste0("papers/",doi,".pdf"))
}, error=function(e){})
if(length(pdftext)==0){
print("         ERROR")
}else{
#Correct errors
#Remove line breaks
pdftext <- gsub("\n"," ",pdftext)
#Change tabs to spaces
pdftext <- gsub("\t"," ",pdftext)
#Correct hyphens
pdftext <- gsub("- ","",pdftext)
#Correct multi-spaces (iterate until no double-spaces are found)
spacecount <- str_count(pdftext, "  ")
while(spacecount > 0){
pdftext <- gsub("  "," ",pdftext)
spacecount <- str_count(pdftext, "  ")
}
#Extract keywords
key_res <- c()
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
if(is.null(key_res){
print("         ERROR")
}else{
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Get keyword statistics
stats <- t(t(table(key_res[1])))
colnames(stats) <- "Counts"
write.csv(stats,paste0("extracts/",doi,".txt"))
#Save extracts to table
keyword_table <- cbind(key_res$keyword,unlist(key_res$line_text))
colnames(keyword_table) <- c("Keyword","Context")
write.csv(keyword_table,paste0("extracts/",doi,".csv"))
}
}
}
####
# Get list of dois
####
doilist <- list.files(path = "papers", pattern = ".pdf",full.names=FALSE)
doilist <- gsub(".pdf","",doilist)
####
# Iterate across dois
####
for(doi in doilist){
print(paste0("Processing paper: ",doi))
#Extract text
pdftext <- c()
tryCatch({
pdftext <- tabulizer::extract_text(paste0("papers/",doi,".pdf"))
}, error=function(e){})
if(length(pdftext)==0){
print("         ERROR")
}else{
#Correct errors
#Remove line breaks
pdftext <- gsub("\n"," ",pdftext)
#Change tabs to spaces
pdftext <- gsub("\t"," ",pdftext)
#Correct hyphens
pdftext <- gsub("- ","",pdftext)
#Correct multi-spaces (iterate until no double-spaces are found)
spacecount <- str_count(pdftext, "  ")
while(spacecount > 0){
pdftext <- gsub("  "," ",pdftext)
spacecount <- str_count(pdftext, "  ")
}
#Extract keywords
key_res <- c()
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
if(is.null(key_res)){
print("         ERROR")
}else{
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Get keyword statistics
stats <- t(t(table(key_res[1])))
colnames(stats) <- "Counts"
write.csv(stats,paste0("extracts/",doi,".txt"))
#Save extracts to table
keyword_table <- cbind(key_res$keyword,unlist(key_res$line_text))
colnames(keyword_table) <- c("Keyword","Context")
write.csv(keyword_table,paste0("extracts/",doi,".csv"))
}
}
}
key_res
key_res <- keyword_search(pdftext, keyword = keywords)
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
key_res
key_res <- c()
key_res
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
key_res
©doilist
doilist
stats
####
# Define keywords
####
keywords = c('wild', 'fitness', 'adaptation','mutant','inbred','model')
####
# Get list of dois
####
doilist <- list.files(path = "papers", pattern = ".pdf",full.names=FALSE)
doilist <- gsub(".pdf","",doilist)
####
# Iterate across dois
####
statstable <- c()
for(doi in doilist){
print(paste0("Processing paper: ",doi))
#Extract text
pdftext <- c()
tryCatch({
pdftext <- tabulizer::extract_text(paste0("papers/",doi,".pdf"))
}, error=function(e){})
if(length(pdftext)==0){
print("         ERROR")
}else{
#Correct errors
#Remove line breaks
pdftext <- gsub("\n"," ",pdftext)
#Change tabs to spaces
pdftext <- gsub("\t"," ",pdftext)
#Correct hyphens
pdftext <- gsub("- ","",pdftext)
#Correct multi-spaces (iterate until no double-spaces are found)
spacecount <- str_count(pdftext, "  ")
while(spacecount > 0){
pdftext <- gsub("  "," ",pdftext)
spacecount <- str_count(pdftext, "  ")
}
#Extract keywords
key_res <- c()
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
if(is.null(key_res)){
print("         ERROR")
}else{
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Get keyword statistics
stats <- t(t(table(key_res[1])))
colnames(stats) <- "Counts"
write.csv(stats,paste0("extracts/",doi,".txt"))
#Save extracts to table
keyword_table <- cbind(key_res$keyword,unlist(key_res$line_text))
colnames(keyword_table) <- c("Keyword","Context")
write.csv(keyword_table,paste0("extracts/",doi,".csv"))
}
}
}
setwd("/Users/anttonalberdi/github/microbiota_adaptation_review/")
library(stringr)
library(caret)
library(caretEnsemble)
all <- read.csv("data/all_20211025.csv")
##############
# 1 - Get random articles
##############
all.random <- all[sample(1:nrow(all),200),]
write.csv(all.random,"data/all_20211025_random200.csv",row.names=FALSE)
##############
# 2 - Manually inspect whether they match criteria
##############
##############
# 3 - Load and modify response data
##############
all.random <- read.csv("data/all_20211025_random200.csv")
all.random <- all.random[,c("Title","DOI","Keywords","Response")]
rownames(all.random) <- all.random$DOI
#Get all keywords
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")
allkeywords <- gsub("\"","",allkeywords)
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))
allkeywords <- allkeywords[allkeywords != ""]
#Create keyword matrix
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))
colnames(all.matrix) <- allkeywords
rownames(all.matrix) <- all.random$DOI
#Populate matrix
for (d in all.random$DOI){
for (k in allkeywords){
if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){
all.matrix[d,k] = 1
}else{
all.matrix[d,k] = 0
}
}
}
head(all.matrix)
doilist <- list.files(path = "extracts", pattern = ".txt",full.names=FALSE)
doilist <- gsub(".txt","",doilist)
doilist
doi=doilist[1]
stats <- read.table(paste0("extracts/",doi,".txt"))
stats
stats <- read.table(paste0("extracts/",doi,".txt"),header=TRUE,sep=",")
stats
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
countsvector <- c(countsvector,counts)
}
countsvector
key
counts <- stats[stats$X == key,"Counts"]
counts
key="bla"
counts <- stats[stats$X == key,"Counts"]
counts
is.null(counts)
is.empty(counts)
if(!counts>0){counts=0}
if not(counts>0){counts=0}
if(!(counts>0)){counts=0}
counts
length(counts)
if(length(counts)=0){counts=0}
if(length(counts)==0){counts=0}
counts
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
if(length(counts)==0){counts=0}
countsvector <- c(countsvector,counts)
}
countsvector
keywords
for(doi in doilist){
stats <- read.table(paste0("extracts/",doi,".txt"),header=TRUE,sep=",")
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
if(length(counts)==0){counts=0}
countsvector <- c(countsvector,counts)
}
statstable <- rbind(c(doi,countsvector))
}
statstable
doilist <- list.files(path = "extracts", pattern = ".txt",full.names=FALSE)
doilist <- gsub(".txt","",doilist)
for(doi in doilist){
stats <- read.table(paste0("extracts/",doi,".txt"),header=TRUE,sep=",")
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
if(length(counts)==0){counts=0}
countsvector <- c(countsvector,counts)
}
statstable <- rbind(statstable,c(doi,countsvector))
}
statstable
ç
doilist <- list.files(path = "extracts", pattern = ".txt",full.names=FALSE)
doilist <- gsub(".txt","",doilist)
#Create empty stats table
statstable <- c()
for(doi in doilist){
stats <- read.table(paste0("extracts/",doi,".txt"),header=TRUE,sep=",")
#Get stats
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
if(length(counts)==0){counts=0}
countsvector <- c(countsvector,counts)
}
#Add stats to table
statstable <- rbind(statstable,c(doi,countsvector))
}
colnames(statstable) <- keywords
statstable
doilist <- list.files(path = "extracts", pattern = ".txt",full.names=FALSE)
doilist <- gsub(".txt","",doilist)
#Create empty stats table
statstable <- c()
for(doi in doilist){
stats <- read.table(paste0("extracts/",doi,".txt"),header=TRUE,sep=",")
#Get stats
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
if(length(counts)==0){counts=0}
countsvector <- c(countsvector,counts)
}
#Add stats to table
statstable <- rbind(statstable,countsvector)
}
colnames(statstable) <- keywords
rownames(statstable) <- doilist
statstable
####
# Define keywords
####
keywords = c('wild', 'fitness', 'adaptation','mutant','inbred','model','c57bl','knockout','disease model')
####
# Get list of dois
####
doilist <- list.files(path = "papers", pattern = ".pdf",full.names=FALSE)
doilist <- gsub(".pdf","",doilist)
####
# Iterate across dois
####
statstable <- c()
for(doi in doilist){
print(paste0("Processing paper: ",doi))
#Extract text
pdftext <- c()
tryCatch({
pdftext <- tabulizer::extract_text(paste0("papers/",doi,".pdf"))
}, error=function(e){})
if(length(pdftext)==0){
print("         ERROR")
}else{
#Correct errors
#Remove line breaks
pdftext <- gsub("\n"," ",pdftext)
#Change tabs to spaces
pdftext <- gsub("\t"," ",pdftext)
#Correct hyphens
pdftext <- gsub("- ","",pdftext)
#Correct multi-spaces (iterate until no double-spaces are found)
spacecount <- str_count(pdftext, "  ")
while(spacecount > 0){
pdftext <- gsub("  "," ",pdftext)
spacecount <- str_count(pdftext, "  ")
}
#Extract keywords
key_res <- c()
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
if(is.null(key_res)){
print("         ERROR")
}else{
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Get keyword statistics
stats <- t(t(table(key_res[1])))
colnames(stats) <- "Counts"
write.csv(stats,paste0("extracts/",doi,".txt"))
#Save extracts to table
keyword_table <- cbind(key_res$keyword,unlist(key_res$line_text))
colnames(keyword_table) <- c("Keyword","Context")
write.csv(keyword_table,paste0("extracts/",doi,".csv"))
}
}
}
doilist <- list.files(path = "extracts", pattern = ".txt",full.names=FALSE)
doilist <- gsub(".txt","",doilist)
#Create empty stats table
statstable <- c()
for(doi in doilist){
stats <- read.table(paste0("extracts/",doi,".txt"),header=TRUE,sep=",")
#Get stats
countsvector <- c()
for(key in keywords){
counts <- stats[stats$X == key,"Counts"]
if(length(counts)==0){counts=0}
countsvector <- c(countsvector,counts)
}
#Add stats to table
statstable <- rbind(statstable,countsvector)
}
colnames(statstable) <- keywords
rownames(statstable) <- doilist
statstable
####
# Define keywords
####
keywords = c('wild', 'fitness', 'adaptat','mutant','inbred','model','c57bl','knockout','disease','environment')
####
# Get list of dois
####
doilist <- list.files(path = "papers", pattern = ".pdf",full.names=FALSE)
doilist <- gsub(".pdf","",doilist)
####
# Iterate across dois
####
statstable <- c()
for(doi in doilist){
print(paste0("Processing paper: ",doi))
#Extract text
pdftext <- c()
tryCatch({
pdftext <- tabulizer::extract_text(paste0("papers/",doi,".pdf"))
}, error=function(e){})
if(length(pdftext)==0){
print("         ERROR")
}else{
#Correct errors
#Remove line breaks
pdftext <- gsub("\n"," ",pdftext)
#Change tabs to spaces
pdftext <- gsub("\t"," ",pdftext)
#Correct hyphens
pdftext <- gsub("- ","",pdftext)
#Correct multi-spaces (iterate until no double-spaces are found)
spacecount <- str_count(pdftext, "  ")
while(spacecount > 0){
pdftext <- gsub("  "," ",pdftext)
spacecount <- str_count(pdftext, "  ")
}
#Extract keywords
key_res <- c()
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
if(is.null(key_res)){
print("         ERROR")
}else{
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Get keyword statistics
stats <- t(t(table(key_res[1])))
colnames(stats) <- "Counts"
write.csv(stats,paste0("extracts/",doi,".txt"))
#Save extracts to table
keyword_table <- cbind(key_res$keyword,unlist(key_res$line_text))
colnames(keyword_table) <- c("Keyword","Context")
write.csv(keyword_table,paste0("extracts/",doi,".csv"))
}
}
}
####
# Define keywords
####
keywords = c('wild', 'fitness', 'adaptat','mutant','inbred','model','c57bl','knockout','disease','environment','human','laboratory')
####
# Get list of dois
####
doilist <- list.files(path = "papers", pattern = ".pdf",full.names=FALSE)
doilist <- gsub(".pdf","",doilist)
####
# Iterate across dois
####
statstable <- c()
for(doi in doilist){
print(paste0("Processing paper: ",doi))
#Extract text
pdftext <- c()
tryCatch({
pdftext <- tabulizer::extract_text(paste0("papers/",doi,".pdf"))
}, error=function(e){})
if(length(pdftext)==0){
print("         ERROR")
}else{
#Correct errors
#Remove line breaks
pdftext <- gsub("\n"," ",pdftext)
#Change tabs to spaces
pdftext <- gsub("\t"," ",pdftext)
#Correct hyphens
pdftext <- gsub("- ","",pdftext)
#Correct multi-spaces (iterate until no double-spaces are found)
spacecount <- str_count(pdftext, "  ")
while(spacecount > 0){
pdftext <- gsub("  "," ",pdftext)
spacecount <- str_count(pdftext, "  ")
}
#Extract keywords
key_res <- c()
tryCatch({
key_res <- keyword_search(pdftext, keyword = keywords)
}, error=function(e){})
if(is.null(key_res)){
print("         ERROR")
}else{
#Write document
write.table(pdftext,paste0("texts/",doi,".txt"),col.names=FALSE,row.names=FALSE)
#Get keyword statistics
stats <- t(t(table(key_res[1])))
colnames(stats) <- "Counts"
write.csv(stats,paste0("extracts/",doi,".txt"))
#Save extracts to table
keyword_table <- cbind(key_res$keyword,unlist(key_res$line_text))
colnames(keyword_table) <- c("Keyword","Context")
write.csv(keyword_table,paste0("extracts/",doi,".csv"))
}
}
}
