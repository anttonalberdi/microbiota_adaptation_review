pattern="fastq"
filtFs_list <- gsub(paste("_1.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_1.",pattern,sep=""), full.names=TRUE))
filtFs_list
filtFs <- paste(filtFs_list,paste("_1.",pattern,sep=""),sep="")
filtFs
filtRs <- paste(filtFs_list,paste("_2.",pattern,sep=""),sep="")
filtRs
setequal(filtFs_list, filtRs_list)
filtFs_list <- gsub(paste("_1.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_1.",pattern,sep=""), full.names=TRUE))#
filtRs_list <- gsub(paste("_2.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_2.",pattern,sep=""), full.names=TRUE))
filtFs_list
filtRs_list
setequal(filtFs_list, filtRs_list)
dir
filtFs_list <- gsub(paste("_1.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_1.",pattern,sep=""), full.names=TRUE))#
filtRs_list <- gsub(paste("_2.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_2.",pattern,sep=""), full.names=TRUE))
filtFs_list
filtRs_list
if (setequal(filtFs_list, filtRs_list) == TRUE){#
  filtFs <- paste(filtFs_list,paste("_1.",pattern,sep=""),sep="")#
  filtRs <- paste(filtFs_list,paste("_2.",pattern,sep=""),sep="")#
}else{#
  print("ERROR! The forward and reverse reads do not match")#
}
filtFs
filtRs
paste("_1.",pattern,sep="")
dir="/Users/anttonalberdi/cliptest/3-DADA2"
filelist <- list.files(path = dir, pattern = ".rds", full.names=TRUE)#
SequenceTableList <- lapply(filelist,readRDS)
library(dada2)
trimtablist <- c("A.rev.csv","B.rev.csv","C.csv")
trimtablist[!grepl("rev.csv",trimtablist)]
table <- read.csv("~/Downloads/exercise.csv")
table
table <- read.csv("~/Downloads/exercise.csv",row.names=1,header=TRUE)
table
library(g)
library(hilldiv)
hill_div(table,qvalue=0)
hill_div(table,qvalue=1)
hill_div(table,qvalue=2)
table <- read.csv("~/Downloads/exercise.csv",row.names=1,header=TRUE)
table
library(hilldiv)
hill_div(table,qvalue=0)
hill_div(table,qvalue=1)
hill_div(table,qvalue=2)
hill_div(table,qvalue=0.5)
hill_div(table,qvalue=0)
hill_div(table,qvalue=0.1)
hill_div(table,qvalue=0.2)
hill_div(table,qvalue=0.32)
hill_div(table,qvalue=0.4)
hill_div(table,qvalue=0.5)
hill_div(table,qvalue=1)
hill_div(table,qvalue=2)
base <- c(496,134,548,414,962,859,1784)
hist(base)
dlnorm(4, meanlog = 0, sdlog = 1)
t.test(c(1.87,2.42,2.92),c(3.29,2.8,3.33,2.96))
hist(dnorm(100, 2028.8, 322.37))
dnorm(100, 2028.8, 322.37)
dnorm(c(1:1000), 2028.8, 322.37)
hist(dnorm(c(1:1000), 2028.8, 322.37))
hist(rnorm(1000, 2028.8, 322.37))
hist(rnorm(1000, 2661.4, 265.39))
hist(rnorm(1000, 2562.3, 368.56))
hist(rnorm(1000, 2076.7, 343.17))
pdf("hist.pdf",weight=8,height=6)
pdf("hist.pdf",width=8,height=6)
hist(rnorm(1000, 2076.7, 343.17))
dev.off()
pdf("hist.pdf",width=8,height=6)
hist(rnorm(1000, 2212.6, 328.22))
dev.off()
library(hier.part )
library(hier.part)
install.packages("hier.part")
library(hier.part)
data(urbanwq)#
    env <- urbanwq[,2:8]
env
example <- read.csv(""~/Downloads/example.csv")
example <- read.csv("~/Downloads/example.csv")
example
example <- read.csv("~/Downloads/example.csv")
example
aov(Chicken.body.weight ~ Pen * Replicate * Trial, data = example)
summary(aov(Chicken.body.weight ~ Pen * Replicate * Trial, data = example))
summary(aov(Chicken.body.weight ~ Pen + Replicate + Trial, data = example))
library(lme4)
fit = lmer(Chicken.body.weight ~ Pen + (Pen | Trial),  example)
fit
VarCorrCI(fit)
library(nlme)
subset <- read.csv("~/Downloads/samples.tsv")
head(subset)
subset <- read.csv("~/Downloads/samples.tsv",row.names=1)
head(subset)
subset <- read.csv("~/Downloads/samples.tsv")
head(subset)
subset <- read.tabe("~/Downloads/samples.tsv",row.names=1)
subset <- read.table("~/Downloads/samples.tsv",row.names=1)
head(subset)
asvtable <- read.table("~/Downloads/ASVs_counts_default_223_223.tsv")
head(asvtable)
colnames(asvtable)
samples <- colnames(asvtable)
head(samples)
samples <- grep(samples,"_rev$")
samples <- colnames(asvtable)#
samples <- grep("_rev$",samples)
samples
samples <- grep("_rev$",samples,values=T)
samples <- colnames(asvtable)#
samples <- grep("_rev$",samples,values=T)
samples <- colnames(asvtable)#
samples <- grep("_rev$",samples,value=T)
samples
samples <- grep("_rev$",samples,value=T)#
samples <- gsub("_rev$","",samples)
samples
samples <- colnames(asvtable)#
samples1 <- grep("_rev$",samples,value=T)#
samples2 <- gsub("_rev$","",samples1)
samples1
samples <- colnames(asvtable)#
samples2 <- grep("_rev$",samples,value=T)#
samples1 <- gsub("_rev$","",samples2)
samples1
samples2
samples <- sort(is colnames(asvtable))#
samples2 <- grep("_rev$",samples,value=T)#
samples1 <- gsub("_rev$","",samples2)
samples <- sort(colnames(asvtable))#
samples2 <- grep("_rev$",samples,value=T)#
samples1 <- gsub("_rev$","",samples2)
samples1
samples2
length(samples1)
i=1
sum(asvtable[,samples1[i]],asvtable[,samples2[i]])
asvtable[,samples1[i]
asvtable[,samples1[i]]
asvtable[,samples2[i]]
newcol = asvtable[,samples1[i]] + asvtable[,samples2[i]]
newcol
mergedasvtable <- c()#
for(i in c(1:length(samples1))){#
newcol = asvtable[,samples1[i]] + asvtable[,samples2[i]]#
cbind(mergedasvtable,samples1[i]= newcol)#
}
mergedasvtable <- c()#
for(i in c(1:length(samples1))){#
newcol = asvtable[,samples1[i]] + asvtable[,samples2[i]]#
mergedasvtable <- cbind(mergedasvtable,samples1[i]= newcol)#
}
c(1:length(samples1)
)
for(i in c(1:length(samples1))){#
newcol = asvtable[,samples1[i]] + asvtable[,samples2[i]]#
#
#mergedasvtable <- cbind(mergedasvtable, samples1[i] = newcol)#
}
newcol
newcol = t(asvtable[,samples1[i]] + asvtable[,samples2[i]])
newcol
newcol = t(t(asvtable[,samples1[i]] + asvtable[,samples2[i]]))
newcol
colnames(newcol) <- samples1[i]
head(newcol)
mergedasvtable <- c()#
for(i in c(1:length(samples1))){#
newcol = t(t(asvtable[,samples1[i]] + asvtable[,samples2[i]]))#
colnames(newcol) <- samples1[i]#
mergedasvtable <- cbind(mergedasvtable, newcol)#
}
head(mergedasvtable)
setwd("/Users/anttonalberdi/github/microbiota_adaptation_review/")#
#
all <- read.csv("data/all_20211025.csv")
head(all)
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords")]#
#
#Get all keywords#
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
#
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords)+3,nrow=nrow(all.random))#
colnames(all.matrix) <- c(c("Title","DOI","Result"),allkeywords)#
rownames(all.matrix) <- all.random$DOI
head(all.matrix)
d=10.1007/s10482-016-0698-1
d="10.1007/s10482-016-0698-1"
all.random[d,"Keywords"
]
all.random[d,]
all.matrix[d,"Keywords"]
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords)+4,nrow=nrow(all.random))#
colnames(all.matrix) <- c(c("Title","DOI","Result","Keywords"),allkeywords)#
rownames(all.matrix) <- all.random$DOI
all.matrix[d,"Keywords"]
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI
head(all.random )
all.random <- all.random[,c("Title","DOI","Keywords")]#
rownames(all.random) <- all.random$DOI
all.random[d,"Keywords"]
str_split(all.random[d,"Keywords"], ";")
library(stringr)
str_split(all.random[d,"Keywords"], ";")
gsub("^ ","",str_split(all.random[d,"Keywords"], ";"))
trimws(str_split(all.random[d,"Keywords"], ";"))
str_split(all.random[d,"Keywords"], ";")
unlist(str_split(all.random[d,"Keywords"], ";")))
str_split(all.random[d,"Keywords"], ";"))
unlist(str_split(all.random[d,"Keywords"], ";")))
unlist(str_split(all.random[d,"Keywords"], ";"))
trimws(unlist(str_split(all.random[d,"Keywords"], ";")))
all.matrix[d,k] %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))
k=allkeywords[1]
all.matrix[d,k] %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))
all.matrix[d,k]
k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI#
#
#Populate matrix#
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}#
}
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}#
}
d
k
allkeywords
k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))
all.matrix[d,k]
head(all.matrix)
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[complete.cases(allkeywords)]
head(allkeywords)
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[allkeywords != ""]
head(allkeywords)
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI#
#
#Populate matrix#
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}#
}
head(all.matrix)
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords","Response")]#
rownames(all.random) <- all.random$DOI#
#
#Get all keywords#
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[allkeywords != ""]#
#
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI
all.matrix$Response_variable <- all.random$Response
head(all.random$Response)
all.matrix$Response_variable
all.matrix
all.random$Response
###############
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords","Response")]#
rownames(all.random) <- all.random$DOI#
#
#Get all keywords#
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[allkeywords != ""]#
#
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI#
#
#Populate matrix#
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}#
}#
#
#Add response colum#
all.matrix <- as.data.frame(all.matrix)#
all.matrix$Response_variable <- all.random$Response
head(all.matrix)
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.4)
split
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.4)#
train <- all.matrix[split,]#
test <- all.matrix[-split,]
nrow(train)
nrow(test)
library(caret)
install.packages(caret)
install.packages("caret")
library(caret)
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)
cv
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10), #
  loss = "L2_primal", #
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))
install.packages("caretEnsemble")
library(caretEnsemble)
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))
model_list <- caretList(#
  Response~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
head(train)
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response_variable), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10), #
  loss = "L2_primal", #
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10), #
  loss = "L2_primal", #
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
results <- resamples(model_list[c(1:3)])
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.4)#
train <- all.matrix[split,]#
train$Response_variable <- as.factor(as.character(train$Response_variable))#
test <- all.matrix[-split,]#
test$Response_variable <- as.factor(as.character(test$Response_variable))#
#
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response_variable), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)#
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10), #
  loss = "L2_primal", #
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
head(train)
train$Response_variable
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
model_list
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords","Response")]#
rownames(all.random) <- all.random$DOI#
#
#Get all keywords#
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[allkeywords != ""]#
#
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI#
#
#Populate matrix#
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = "Yes"#
    }else{#
      all.matrix[d,k] = "No"#
    }#
}#
}#
#
#Add response colum#
all.matrix <- as.data.frame(all.matrix)#
all.matrix$Response_variable <- all.random$Response
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.4)#
train <- all.matrix[split,]#
train$Response_variable <- as.factor(as.character(train$Response_variable))#
test <- all.matrix[-split,]#
test$Response_variable <- as.factor(as.character(test$Response_variable))#
#
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response_variable), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)#
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10),#
  loss = "L2_primal",#
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
train$Response_variable
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords","Response")]#
rownames(all.random) <- all.random$DOI
all.matrix$Response_variable <- all.random$Response
all.matrix$Response_variable
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.4)#
train <- all.matrix[split,]#
train$Response_variable <- as.factor(as.character(train$Response_variable))#
test <- all.matrix[-split,]#
test$Response_variable <- as.factor(as.character(test$Response_variable))#
#
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response_variable), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)#
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10),#
  loss = "L2_primal",#
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
train$Response_variable
test$Response_variable
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.6)#
train <- all.matrix[split,]#
train$Response_variable <- as.factor(as.character(train$Response_variable))#
test <- all.matrix[-split,]#
test$Response_variable <- as.factor(as.character(test$Response_variable))#
#
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response_variable), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)#
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10),#
  loss = "L2_primal",#
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
train$Response_variable
test$Response_variable
factor(train$Response_variable)
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords","Response")]#
rownames(all.random) <- all.random$DOI#
#
#Get all keywords#
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[allkeywords != ""]#
#
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI#
#
#Populate matrix#
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}#
}
rowSums(all.matrix)
nrow(all.matrix)
all.matrix <- all.matrix[rowSums(all.matrix) != 0,]
nrow(all.matrix)
all.matrix$Response_variable <- all.random[rownames(all.matrix),"Response"]
all.random <- read.csv("data/all_20211025_random200_test.csv")#
all.random <- all.random[,c("Title","DOI","Keywords","Response")]#
rownames(all.random) <- all.random$DOI#
#
#Get all keywords#
allkeywords <- paste(shQuote(all.random$Keywords), collapse="; ")#
allkeywords <- gsub("\"","",allkeywords)#
allkeywords <- unique(sort(unlist(strsplit(allkeywords, split="; "))))#
allkeywords <- allkeywords[allkeywords != ""]#
#
#Create keyword matrix#
all.matrix <- matrix(ncol=length(allkeywords),nrow=nrow(all.random))#
colnames(all.matrix) <- allkeywords#
rownames(all.matrix) <- all.random$DOI#
#
#Populate matrix#
for (d in all.random$DOI){#
  for (k in allkeywords){#
    if(k %in% trimws(unlist(str_split(all.random[d,"Keywords"], ";")))){#
      all.matrix[d,k] = 1#
    }else{#
      all.matrix[d,k] = 0#
    }#
}#
}
all.random[rownames(all.matrix),"Response"]
all.matrix <- as.data.frame(all.matrix)#
all.matrix <- all.matrix[rowSums(all.matrix) != 0,]
all.random[rownames(all.matrix),"Response"]
all.matrix$Response_variable <- all.random[rownames(all.matrix),"Response"]
#######
#
split <- sample(1:nrow(all.matrix),nrow(all.matrix)*0.6)#
train <- all.matrix[split,]#
train$Response_variable <- as.factor(as.character(train$Response_variable))#
test <- all.matrix[-split,]#
test$Response_variable <- as.factor(as.character(test$Response_variable))#
#
folds <- 7#
cvIndex <- createMultiFolds(factor(train$Response_variable), folds, times=100)#
cv <- trainControl(method="repeatedcv",#
                     number=folds,#
                     index = cvIndex,#
                     returnResamp="final",#
                     classProbs=TRUE,#
                     summaryFunction=twoClassSummary,#
                     indexFinal=NULL,#
                     savePredictions = TRUE)#
#TuneGrids#
grid_rf <-  expand.grid(mtry = c(80,500,1000,1500))#
grid_lr <- expand.grid(cost = c(0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1, 10),#
  loss = "L2_primal",#
  epsilon = 0.01)#
grid_xgb <-  expand.grid(nrounds=500,#
  gamma=0,#
  eta=c(0.001, 0.01, 0.1, 1),#
  max_depth=8,#
  colsample_bytree= 0.8,#
  min_child_weight=1,#
  subsample=c(0.4, 0.5, 0.6, 0.7))#
#
tuneList <- list(#
  rf=caretModelSpec(method="rf", tuneGrid=grid_rf),#
  lr=caretModelSpec(method="regLogistic", tuneGrid=grid_lr),#
  xgb=caretModelSpec(method="xgbTree", tuneGrid=grid_xgb))#
#
model_list <- caretList(#
  Response_variable~., data=train,#
  trControl=cv,#
  methodList=c("rf", "regLogistic","xgbTree"),#
  tuneList=tuneList)
head(all.random)
head(all.matrix)
